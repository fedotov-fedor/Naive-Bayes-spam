### Описание проекта: Классификация писем на спам с помощью наивного байесовского классификатора

Проект: Реализация модели классификации писем на спам с использованием наивного байесовского классификатора на данных из Kaggle.

Цель: Разработать и внедрить модель для автоматической классификации электронных писем на спам (spam) и не-спам (ham). Основная задача — улучшить качество классификации, минимизировав количество ложных срабатываний (false positives) и пропущенных спамов (false negatives).

### Этапы проекта:

1. Предварительный анализ данных:
   - Выполнен анализ распределения классов (спам и не-спам) с визуализацией через barplot, чтобы выявить возможный дисбаланс данных.
   
2. Частотный анализ слов:
   - Построен частотный словарь, отражающий, какие слова чаще всего встречаются в письмах, чтобы лучше понять важность слов для классификации.

3. Реализация наивного байесовского классификатора:
   - Наивный байесовский классификатор был реализован вручную, без использования сторонних библиотек, для лучшего понимания процесса классификации.
   - Модель основана на вероятностном подходе, где каждый токен (слово) в письме оценивается с точки зрения его вероятности появления в спам-письмах и обычных письмах.

4. Оценка модели:
   - Построена ROC-кривая, на которой видно, как модель классифицирует письма при разных порогах вероятности.
   - Значение roc_auc_score = 0.93 указывает на высокую способность модели различать классы (спам и не-спам).
   
5. Дополнительные метрики:
   - Построена confusion_matrix для наглядного отображения результатов классификации и оценки ошибок модели.
   - Выведен classification_report, включающий метрики precision, recall, f1-score и accuracy. Модель показала высокое значение accuracy = 0.97, что свидетельствует о ее точности при классификации писем.

### Результаты:
- Реализованный с нуля наивный байесовский классификатор показал отличные результаты при классификации писем, достигая roc_auc_score = 0.93 и accuracy = 0.97.
- Модель эффективно разделяет спам и не-спам письма, минимизируя количество ошибок классификации.
